#!/usr/bin/env python3
import argparse
import os
import numpy as np
import scipy.integrate
import random
import multiprocessing
import sys

sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'lib'))
import common
import inputparser
import tree_sampler
import clustermaker
import resultserializer
import hyperparams
import util

def _parse_args():
  parser = argparse.ArgumentParser(
    description='Build clone trees',
    formatter_class=argparse.ArgumentDefaultsHelpFormatter
  )
  parser.add_argument('--verbose', action='store_true',
    help='Print debugging messages')
  parser.add_argument('--seed', dest='seed', type=int,
    help='Integer seed used for pseudo-random number generator. Running Pairtree with the same seed on the same inputs will produce exactly the same result.')
  parser.add_argument('--parallel', dest='parallel', type=int, default=None,
    help='Number of tasks to run in parallel. By default, this is set to the number of CPU cores on the system. On hyperthreaded systems, this will be twice the number of physical CPUs.')
  parser.add_argument('--params', dest='params_fn',
    help='Path to JSON-formatted parameters (including mutation clusters and sample names).')
  parser.add_argument('--trees-per-chain', dest='trees_per_chain', type=int, default=3000,
    help='Total number of trees to sample in each MCMC chain.')
  parser.add_argument('--tree-chains', dest='tree_chains', type=int, default=None,
    help='Number of MCMC chains to run.')
  parser.add_argument('--burnin', dest='burnin', type=float, default=(1/3),
    help='Proportion of samples to discard from beginning of each chain.')
  parser.add_argument('--thinned-frac', dest='thinned_frac', type=float, default=1,
    help='Proportion of non-burnin trees to write as output.')
  parser.add_argument('--phi-fitter', dest='phi_fitter', choices=('projection', 'rprop', 'proj_rprop', 'debug', 'graddesc_old', 'rprop_old'), default='projection')
  parser.add_argument('--phi-iterations', dest='phi_iterations', type=int, default=10000,
    help='Maximum number of iterations of phi-fitting algorithm to run when using iterative phi-fitting algorithms (rprop or proj_rprop).')
  parser.add_argument('--only-build-tensor', dest='only_build_tensor', action='store_true',
    help='Exit after building pairwise relations tensor, without sampling any trees.')
  parser.add_argument('--disable-posterior-sort', dest='sort_by_llh', action='store_false',
    help='Disable sorting posterior tree samples by descending probability, and instead list them in the order they were sampled)')
  for K in hyperparams.defaults.keys():
    parser.add_argument('--%s' % K, type=float, default=hyperparams.defaults[K], help=hyperparams.explanations[K])

  parser.add_argument('ssm_fn')
  parser.add_argument('results_fn')
  args = parser.parse_args()
  return args

def _init_hyperparams(args):
  for K in hyperparams.defaults.keys():
    V = getattr(args, K)
    setattr(hyperparams, K, V)

def main():
  np.set_printoptions(linewidth=400, precision=3, threshold=sys.maxsize, suppress=True)
  np.seterr(divide='raise', invalid='raise', over='raise')

  args = _parse_args()
  _init_hyperparams(args)
  common.debug.DEBUG = args.verbose

  # Note that multiprocessing.cpu_count() returns number of logical cores, so
  # if you're using a hyperthreaded CPU, this will be more than the number of
  # physical cores you have.
  parallel = args.parallel if args.parallel is not None else multiprocessing.cpu_count()
  if args.tree_chains is not None:
    tree_chains = args.tree_chains
  else:
    # We sometimes set `parallel = 0` to disable the use of multiprocessing,
    # making it easier to read debug messages.
    tree_chains = max(1, parallel)

  if args.seed is not None:
    seed = args.seed
  else:
    # Maximum seed is 2**32 - 1.
    seed = np.random.randint(2**32)
  np.random.seed(seed)
  random.seed(seed)

  variants = inputparser.load_ssms(args.ssm_fn)
  common.debug._truthfn = args.ssm_fn.replace('.ssm', '.data.pickle')
  params = inputparser.load_params(args.params_fn)
  logprior = {'garbage': -np.inf, 'cocluster': -np.inf}

  results = resultserializer.Results(args.results_fn)
  results.add('seed', seed)
  results.save()

  if not results.has('sampnames'):
    assert 'samples' in params
    results.add('sampnames', params['samples'])

  if results.has_mutrel('clustrel_posterior') and results.has_mutrel('clustrel_evidence') and results.has('clusters') and results.has('garbage'):
    clustrel_posterior = results.get_mutrel('clustrel_posterior')
    clustrel_evidence = results.get_mutrel('clustrel_evidence')
    clusters = results.get('clusters')
    garbage = results.get('garbage')
    supervars = clustermaker.make_cluster_supervars(clusters, variants)
  else:
    assert 'clusters' in params and 'garbage' in params, 'Clusters not provided'
    supervars, clustrel_posterior, clustrel_evidence, clusters, garbage = clustermaker.use_pre_existing(
      variants,
      logprior,
      parallel,
      params['clusters'],
      params['garbage'],
    )
    results.add_mutrel('clustrel_posterior', clustrel_posterior)
    results.add_mutrel('clustrel_evidence', clustrel_evidence)
    results.add('clusters', clusters)
    results.add('garbage', garbage)
    results.save()

  if args.only_build_tensor:
    sys.exit()

  superclusters = clustermaker.make_superclusters(supervars)
  # Add empty initial cluster, which serves as tree root.
  superclusters.insert(0, [])

  if not results.has('struct'):
    if 'structures' not in params:
      adjm, phi, llh, accept_rate = tree_sampler.sample_trees(
        clustrel_posterior,
        supervars,
        superclusters,
        args.trees_per_chain,
        args.burnin,
        tree_chains,
        args.thinned_frac,
        args.phi_fitter,
        args.phi_iterations,
        seed,
        parallel,
      )
      results.add('accept_rate', accept_rate)
    else:
      adjms = [util.convert_parents_to_adjmatrix(struct) for struct in params['structures']]
      adjm, phi, llh = tree_sampler.use_existing_structures(
        adjms,
        supervars,
        superclusters,
        args.phi_fitter,
        args.phi_iterations,
        parallel
      )

    post_struct, post_count, post_phi, post_llh, post_prob = tree_sampler.compute_posterior(
      adjm,
      phi,
      llh,
      args.sort_by_llh,
    )
    results.add('struct', post_struct)
    results.add('count', post_count)
    results.add('phi', post_phi)
    results.add('llh', post_llh)
    results.add('prob', post_prob)
    results.save()

if __name__ == '__main__':
  # This is default on Unix but not macOS. Without this, resources aren't
  # inherited by subprocesses on macOS and various things break. However, on
  # macOS, it can cause crashes. See
  # https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods
  # On top of this, MacOS throws an exception since set_start_method is called elsewhere, 
  # adding the argument 'force=True' resolves the exception.
  if sys.platform == "darwin":
    multiprocessing.set_start_method('fork', force=True)
  main()
